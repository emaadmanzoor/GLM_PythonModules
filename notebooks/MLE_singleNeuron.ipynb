{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### This notebook presents how to perform maximum-likelihood parameter estimation for a single neuron."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import random\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "sys.path.append(os.path.join(os.getcwd(),\"..\"))\n",
    "sys.path.append(os.path.join(os.getcwd(),\"..\",\"code\"))\n",
    "data_path = os.path.join(os.getcwd(),'..','data')\n",
    "sys.path.append(data_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import filters\n",
    "import likelihood_functions as lk\n",
    "import PoissonProcessClasses as PP\n",
    "import auxiliary_functions as auxfun"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'PoissonProcessClasses' from '/Users/val/MEGAsync/GLM_PythonModules/notebooks/../code/PoissonProcessClasses.py'>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import imp\n",
    "imp.reload(filters)\n",
    "imp.reload(lk)\n",
    "imp.reload(auxfun)\n",
    "imp.reload(PP)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reading input-output data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# reading stimulus\n",
    "Stim = np.array(pd.read_csv(os.path.join(data_path,'Stim.csv'),header = None))\n",
    "# reading location of spikes\n",
    "tsp = np.hstack(np.array(pd.read_csv(os.path.join(data_path,'tsp.csv'),header = None)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Extracting a spike train from spike positions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "dt = 0.01\n",
    "tsp_int = np.ceil((tsp - dt*0.001)/dt)\n",
    "tsp_int = np.reshape(tsp_int,(tsp_int.shape[0],1))\n",
    "tsp_int = tsp_int.astype(int)\n",
    "y = np.array([item in tsp_int for item in np.arange(Stim.shape[0]/dt)]).astype(int)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Displaying the spike train a subset of the spike train:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creating filters:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# create a stimulus filter\n",
    "kpeaks = np.array([0,round(20/3)])\n",
    "pars_k = {'neye':5,'n':5,'kpeaks':kpeaks,'b':3}\n",
    "K,K_orth,kt_domain = filters.createStimulusBasis(pars_k, nkt = 20) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# create a post-spike filter\n",
    "hpeaks = np.array([0.1,2])\n",
    "pars_h = {'n':5,'hpeaks':hpeaks,'b':.4,'absref':0.}\n",
    "H,H_orth,ht_domain = filters.createPostSpikeBasis(pars_h,dt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Conditional Intensity* (spike rate):\n",
    "\n",
    "$$\\lambda_{\\beta} = \\exp(K(\\beta_k)*Stim + H(\\beta_h)*y)$$\n",
    "\n",
    "($\\beta_k$ and $\\beta_h$ are the unknown coefficients of the filters)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Since the convolution is a linear operation the intensity can be written in the following form:\n",
    "\n",
    "$$\\lambda_{\\beta} = \\exp(M_k \\beta_k + M_h\\beta_h),$$\n",
    "\n",
    "where $M_k$ and $M_h$ are matrices depending on the stimulus and the response correspondingly."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creating a matrix of covariates:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "M_k = lk.construct_M_k(Stim,K,dt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "M_h = lk.construct_M_h(tsp,H_orth,dt,Stim)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "Combining $M_k$ and $M_h$ into one covariate matrix:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "M = np.hstack((M_k,M_h))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The conditional intensity becomes:\n",
    "$$ \\lambda_{\\beta} = \\exp(M\\beta) $$\n",
    "\n",
    "($\\beta$ contains all the unknown parameters)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a Poisson process model with this intensity:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "model = PP.PPModel(M.T,dt = dt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Setting initial parameters for optimization:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "coeff_k0 = np.array([0.32967,\n",
    "    0.59341,\n",
    "    1.36703,\n",
    "    1.78901,\n",
    "    1.33187,\n",
    "    0.66788,\n",
    "   -1.69981,\n",
    "    0.44975,\n",
    "   -0.12650,\n",
    "   -0.05882])\n",
    "# coeff_h0 = np.zeros((5,))\n",
    "coeff_h0 = np.array([-15.18,38.24,-67.58,-14.06,-3.36])\n",
    "\n",
    "pars0 = np.hstack((coeff_k0,coeff_h0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fitting the likelihood (here using Nelder-Mead method with 10000 iterations):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "res = model.fit(y,start_coef = pars0,maxiter = 10000,method = 'Nelder-Mead')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Optimization results:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print(res)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creating the predicted filters:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "k_coeff_predicted = res.x[:10]\n",
    "h_coeff_predicted = res.x[10:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "kfilter_predicted = np.dot(K,k_coeff_predicted)\n",
    "hfilter_predicted = np.dot(H_orth,h_coeff_predicted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "k_coeff = np.array([ 0.061453,0.284916,0.860335,1.256983,0.910615,0.488660,-0.887091,0.097441,0.026607,-0.090147])\n",
    "h_coeff = np.array([-10, -5, 0, 2, -2])\n",
    "\n",
    "kfilter_true = np.dot(K,k_coeff)\n",
    "hfilter_true = np.dot(H_orth,h_coeff)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.plot(kfilter_predicted,color = \"r\",label = 'predicted')\n",
    "plt.hold(True)\n",
    "plt.plot(kfilter_true,color= \"blue\",label = 'true')\n",
    "plt.hold(True)\n",
    "plt.plot(np.dot(K,coeff_k0),color = \"g\",label = 'initial')\n",
    "plt.legend(loc = 'upper left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "hfilter_true = np.dot(H_orth,np.array([-15.18,38.24,-67.58,-14.06,-3.36]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.plot(ht_domain,hfilter_predicted,color = \"r\",label = 'predicted')\n",
    "plt.hold(True)\n",
    "plt.plot(ht_domain,hfilter_true,color = \"b\",label = 'true')\n",
    "plt.hold(True)\n",
    "plt.plot(ht_domain,np.dot(H_orth,coeff_h0),color = \"g\",label = 'initial')\n",
    "plt.legend(loc = 'lower right')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
