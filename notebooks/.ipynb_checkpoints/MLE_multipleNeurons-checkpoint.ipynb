{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### This notebook presents how to perform maximum-likelihood parameter estimation for multiple neurons. \n",
    "#### For testing the concept we use 2 neurons for which we have stored the responses to a given stimulus. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import random\n",
    "import csv\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "sys.path.append(os.path.join(os.getcwd(),\"..\"))\n",
    "sys.path.append(os.path.join(os.getcwd(),\"..\",\"code\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import filters\n",
    "import likelihood_functions as lk\n",
    "import PoissonProcessClasses as PP\n",
    "import auxiliary_functions as auxfun"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'PoissonProcessClasses' from '/Users/val/MEGAsync/GLM_PythonModules/notebooks/../code/PoissonProcessClasses.py'>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import imp\n",
    "imp.reload(filters)\n",
    "imp.reload(lk)\n",
    "imp.reload(auxfun)\n",
    "imp.reload(PP)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Number of neurons\n",
    "nofCells = 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reading input-output data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# creating the path to the data\n",
    "data_path = os.path.join(os.getcwd(),'..','data')\n",
    "\n",
    "# reading stimulus\n",
    "Stim = np.array(pd.read_csv(os.path.join(data_path,'Stim.csv'),header = None))\n",
    "\n",
    "# reading location of spikes\n",
    "# (lengths of tsp sequences are not equal so reading them line by line)\n",
    "tsp_list = []\n",
    "with open(os.path.join(data_path,'tsp2.csv')) as csvfile:\n",
    "    tspreader = csv.reader(csvfile)\n",
    "    for row in tspreader:\n",
    "        tsp_list.append(row)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Extracting a spike train from spike positions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "dt = 0.01\n",
    "y_list = []\n",
    "for tsp in tsp_list:\n",
    "    tsp = np.array(tsp).astype(np.float)\n",
    "    tsp_int = np.ceil((tsp - dt*0.001)/dt)\n",
    "    tsp_int = np.reshape(tsp_int,(tsp_int.shape[0],1))\n",
    "    tsp_int = tsp_int.astype(int)\n",
    "    y_list.append(np.array([item in tsp_int for item in np.arange(Stim.shape[0]/dt)]).astype(int))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creating filters:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# create a stimulus filter\n",
    "kpeaks = np.array([0,round(20/3)])\n",
    "pars_k = {'neye':5,'n':5,'kpeaks':kpeaks,'b':3}\n",
    "K,K_orth,kt_domain = filters.createStimulusBasis(pars_k, nkt = 20) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# create a post-spike filter\n",
    "hpeaks = np.array([0.1,2])\n",
    "pars_h = {'n':5,'hpeaks':hpeaks,'b':.4}\n",
    "H,H_orth,ht_domain = filters.createPostSpikeBasis(pars_h,dt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Conditional Intensity (spike rate):\n",
    "\n",
    "$$\\lambda_{\\beta}(i) = \\exp(K(\\beta_k)*Stim + H(\\beta_h)*y_i + \\sum_{j\\ne i}I({\\beta_{I}}_j)*y_j$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$I(\\beta_{I_j})$ corresponds to an interpolating filter with basis $I$ and  coefficients $\\beta_{I_j}$ associated with the $y_j$ output. It is to assume that the post-spike history basis and the interpolating bases are the same: $H = I$. The intensity can then be rewritten as "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\\lambda_{\\beta}(i) = \\exp\\left(M_k \\beta_k + \\sum_{j=1}^n M_h {\\beta_h}_j\\right)$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creating a matrix of covariates:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!---Simulating a neuron spike trains:-->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "M_k = lk.construct_M_k(Stim,K,dt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# creating a H-matrix for each response and merging them in one covariate matrix M_h\n",
    "M_h_list = []\n",
    "for tsp in tsp_list:\n",
    "    tsp = np.array(tsp).astype(np.float)\n",
    "    M_h_list.append(lk.construct_M_h(tsp,H_orth,dt,Stim))\n",
    "\n",
    "M_h = np.hstack(tuple(M_h_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# combining all covariate matrices\n",
    "M = np.hstack((M_k,M_h))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Conditional intensity as a function of the covariates:\n",
    "$$ \\lambda_{\\beta} = \\exp(M\\beta) $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a Poisson process model with this intensity:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model = PP.PPModel(M.T,dt = dt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Setting initial parameters:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "coeff_k0 = np.array([ 0.061453,0.284916,0.860335,1.256983,0.910615,0.488660,-0.887091,0.097441,0.026607,-0.090147])\n",
    "\n",
    "coeff_h0 = np.zeros((5*nofCells,))\n",
    "\n",
    "pars0 = np.hstack((coeff_k0,coeff_h0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fitting the likelihood for each neuron:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "res_list = []\n",
    "for y in y_list:\n",
    "    res_list.append(model.fit(y,start_coef = pars0,method = 'Nelder-Mead'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "[print('\\n Optimization results:\\n'+str(res)) for res in res_list]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for i in range(len(res_list)):\n",
    "    k_coeff_predicted = res_list[i].x[:10]\n",
    "    h_coeff_predicted = np.reshape(res_list[i].x[10:],(H.shape[1],nofCells))\n",
    "    \n",
    "\n",
    "    fig,axs = plt.subplots(1,2,figsize = (10,5))\n",
    "    fig.suptitle('Neuron%d'%(i+1))\n",
    "    axs[0].plot(-kt_domain[::-1],np.dot(K,k_coeff_predicted))\n",
    "    axs[0].set_title('Stimulus Filter')\n",
    "    axs[0].set_xlabel('Time')\n",
    "    axs[1].plot(ht_domain,np.dot(H,h_coeff_predicted))\n",
    "    axs[1].set_title('Post-Spike Filter')\n",
    "    axs[1].set_xlabel('Time')\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
